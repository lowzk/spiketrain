{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments to test the relationship between various parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pipeline import get_results\n",
    "from helper import read_test_results, display_dicts_as_table\n",
    "\n",
    "with open('config/system_params.json') as f:\n",
    "  system_params = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Baseline static and dynamic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config/baseline_static.json') as f:\n",
    "    baseline_hyperparameters = json.load(f)\n",
    "get_results(baseline_hyperparameters, system_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config/baseline_dynamic.json') as f:\n",
    "    hyperparameters = json.load(f)\n",
    "get_results(hyperparameters, system_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_results = read_test_results('baseline_static')\n",
    "dynamic_results = read_test_results('baseline_dynamic')\n",
    "\n",
    "display_dicts_as_table([static_results, dynamic_results], [\"Static\", \"Dynamic\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights\n",
    "- Accuracy is about the same\n",
    "- Dynamic graphs take a lot longer time to train\n",
    "- Dynamic graphs have more significant memory savings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 MLP vs LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config/lstm_static.json') as f:\n",
    "    hyperparameters = json.load(f)\n",
    "\n",
    "get_results(hyperparameters, system_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config/lstm_dynamic.json') as f:\n",
    "    hyperparameters = json.load(f)\n",
    "\n",
    "get_results(hyperparameters, system_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+--------------------+------------------+--------------+-----------------------+------------------+------------------+--------------------------+---------------+----------------+--------------+---------------+----------------+-----------------+\n",
      "| Name         |   F1 Score (Macro) |   F1 Score (Micro) |   Final accuracy |   Final loss |   Final tensor memory |   Inference MACs |   Memory savings |   Original tensor memory | Saved Nodes   | Saved Spikes   |   Time taken | Total Nodes   | Total Spikes   |   Training MACs |\n",
      "+==============+====================+====================+==================+==============+=======================+==================+==================+==========================+===============+================+==============+===============+================+=================+\n",
      "| Static       |           0.706512 |           0.709275 |          70.9275 |    0.0587753 |               8.57086 |      3.70541e+09 |          5.14252 |                  13.7134 | NIL           | NIL            |      11.596  | NIL           | NIL            |     8.89297e+11 |\n",
      "+--------------+--------------------+--------------------+------------------+--------------+-----------------------+------------------+------------------+--------------------------+---------------+----------------+--------------+---------------+----------------+-----------------+\n",
      "| Static LSTM  |           0.746131 |           0.744882 |          74.4882 |    0.255866  |               8.57086 |      1.04285e+11 |          5.14252 |                  13.7134 | NIL           | NIL            |     191.737  | NIL           | NIL            |     2.50284e+13 |\n",
      "+--------------+--------------------+--------------------+------------------+--------------+-----------------------+------------------+------------------+--------------------------+---------------+----------------+--------------+---------------+----------------+-----------------+\n",
      "| Dynamic      |           0.709199 |           0.719957 |          71.9957 |    0.0770076 |              57.8533  |      2.49286e+10 |        312.408   |                 370.261  | 422494.0      | 13889.0        |      51.2529 | 730210.0      | 58085871.0     |     5.98286e+12 |\n",
      "+--------------+--------------------+--------------------+------------------+--------------+-----------------------+------------------+------------------+--------------------------+---------------+----------------+--------------+---------------+----------------+-----------------+\n",
      "| Dynamic LSTM |           0.730076 |           0.740075 |          74.0075 |    0.104888  |              57.8533  |      7.0384e+11  |        312.408   |                 370.261  | 422494.0      | 13889.0        |    1461.02   | 730210.0      | 58085871.0     |     1.68922e+14 |\n",
      "+--------------+--------------------+--------------------+------------------+--------------+-----------------------+------------------+------------------+--------------------------+---------------+----------------+--------------+---------------+----------------+-----------------+\n"
     ]
    }
   ],
   "source": [
    "static_results = read_test_results('baseline_static')\n",
    "dynamic_results = read_test_results('baseline_dynamic')\n",
    "\n",
    "static_lstm_results = read_test_results('lstm_static')\n",
    "dynamic_lstm_results = read_test_results('lstm_dynamic')\n",
    "\n",
    "display_dicts_as_table([static_results, static_lstm_results, dynamic_results, dynamic_lstm_results], [\"Static\", \"Static LSTM\", \"Dynamic\", \"Dynamic LSTM\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights\n",
    "- LSTM has higher accuracy than MLP\n",
    "- Takes about 20x the amount of time\n",
    "- Best results is static LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Impact of the number of time steps on static graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = [1, 2, 5, 10, 30]\n",
    "\n",
    "for t in timesteps:\n",
    "    with open(f'config/static_ts{t}.json') as f:\n",
    "        hyperparameters = json.load(f)\n",
    "    get_results(hyperparameters, system_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts1_results = read_test_results('static_ts1')\n",
    "ts2_results = read_test_results('static_ts2')\n",
    "ts5_results = read_test_results('static_ts5')\n",
    "ts10_results = read_test_results('static_ts10')\n",
    "ts20_results = read_test_results('baseline_static')\n",
    "ts30_results = read_test_results('static_ts30')\n",
    "\n",
    "display_dicts_as_table([ts1_results, ts2_results, ts5_results, ts10_results, ts20_results, ts30_results], [\"ts=1\", \"ts=2\", \"ts=5\", \"ts=10\", \"ts=20\", \"ts=30\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights\n",
    "- Loss decreases with the number of time steps and is at a minima somewhere around 20\n",
    "- Accuacy (for this dataset) seems to be okay even with lesser time steps\n",
    "- Memory savings decrease with larger time steps (due to more spikes generated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Impact of time steps on dynamic graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps = [1, 2, 3, 4, 5, 10]\n",
    "\n",
    "for t in time_steps:\n",
    "    with open(f'config/lstm_dynamic.json') as f:\n",
    "      hyperparameters = json.load(f)\n",
    "    hyperparameters['time_steps'] = t\n",
    "    hyperparameters[\"hyperparameters_id\"] = f\"dynamic_ts{t}\"\n",
    "    get_results(hyperparameters, system_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts1_results = read_test_results('dynamic_ts1')\n",
    "ts2_results = read_test_results('dynamic_ts2')\n",
    "ts3_results = read_test_results('dynamic_ts3')\n",
    "ts4_results = read_test_results('dynamic_ts4')\n",
    "ts5_results = read_test_results('dynamic_ts5')\n",
    "ts10_results = read_test_results('lstm_dynamic')\n",
    "\n",
    "display_dicts_as_table([ts1_results, ts2_results, ts3_results, ts4_results, ts5_results, ts10_results], [\"ts=1\", \"ts=2\", \"ts=3\", \"ts=4\", \"ts=5\", \"ts=10\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Attempting to get the best version of the model\n",
    "## 5.1 Static\n",
    "- LSTM\n",
    "- Time steps: 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the best model 5 times and get an average\n",
    "with open('config/lstm_static.json') as f:\n",
    "    hyperparameters = json.load(f)\n",
    "    \n",
    "    hyperparameters[\"time_steps\"] = 10\n",
    "    system_params_copy = system_params.copy()\n",
    "    system_params_copy[\"num_epochs\"] = 50\n",
    "\n",
    "for i in range(5):\n",
    "    hyperparameters[\"hyperparameters_id\"] = f\"lstm_static_best_run_{i+1}\"\n",
    "    get_results(hyperparameters, system_params_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the results and average them\n",
    "for i in range(5):\n",
    "    results = read_test_results(f'lstm_static_best_run_{i+1}')\n",
    "    if i == 0:\n",
    "        average_results = results\n",
    "    else:\n",
    "        for key in results:\n",
    "            average_results[key] += results[key]\n",
    "\n",
    "for key in average_results:\n",
    "    average_results[key] /= 5\n",
    "\n",
    "display_dicts_as_table([average_results], [\"Average of 5 runs\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Dynamic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the best model 5 times and get an average\n",
    "with open('config/lstm_dynamic.json') as f:\n",
    "    hyperparameters = json.load(f)\n",
    "    \n",
    "    hyperparameters[\"time_steps\"] = 5\n",
    "    system_params_copy = system_params.copy()\n",
    "    system_params_copy[\"num_epochs\"] = 40\n",
    "\n",
    "for i in range(3):\n",
    "    hyperparameters[\"hyperparameters_id\"] = f\"lstm_dynamic_best_run_{i+1}\"\n",
    "    get_results(hyperparameters, system_params_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the results and average them\n",
    "for i in range(3):\n",
    "    results = read_test_results(f'lstm_dynamic_best_run_{i+1}')\n",
    "    if i == 0:\n",
    "        average_results = results\n",
    "    else:\n",
    "        for key in results:\n",
    "            average_results[key] += results[key]  \n",
    "\n",
    "for key in average_results:\n",
    "    average_results[key] /= 3\n",
    "\n",
    "display_dicts_as_table([average_results], [\"Average of 3 runs\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Reset vs no reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config/baseline_dynamic_noreset.json') as f:\n",
    "    hyperparameters = json.load(f)\n",
    "\n",
    "get_results(hyperparameters, system_params)\n",
    "\n",
    "with open('config/baseline_dynamic.json') as f:\n",
    "    hyperparameters = json.load(f)\n",
    "\n",
    "get_results(hyperparameters, system_params)\n",
    "\n",
    "noreset_results = read_test_results('baseline_dynamic_noreset')\n",
    "reset_results = read_test_results('baseline_dynamic')\n",
    "\n",
    "display_dicts_as_table([noreset_results, reset_results], [\"No Reset\", \"Reset\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config/baseline_dynamic_noreset.json') as f:\n",
    "    hyperparameters = json.load(f)\n",
    "    hyperparameters[\"model\"] = \"LSTM\"\n",
    "    hyperparameters[\"time_steps\"] = 5\n",
    "    hyperparameters[\"hyperparameters_id\"] = \"baseline_dynamic_noreset_lstm\"\n",
    "\n",
    "get_results(hyperparameters, system_params)\n",
    "\n",
    "noreset_results = read_test_results('baseline_dynamic_noreset_lstm')\n",
    "reset_results = read_test_results('lstm_dynamic')\n",
    "\n",
    "display_dicts_as_table([noreset_results, reset_results, read_test_results('baseline_dynamic_noreset_lstm'), read_test_results('lstm_dynamic')], [\"No Reset\", \"Reset\", \"No Reset LSTM\", \"LSTM\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking\n",
    "\n",
    "- Dynamic LSTM, Average of 3, using test_size 0.2, 0.4, 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhekailow/Documents/University/FYP/submission/.venv/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/Users/zhekailow/Documents/University/FYP/submission/.venv/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 1.0905\n",
      "Epoch [2/20], Loss: 0.8869\n",
      "Epoch [3/20], Loss: 0.8139\n",
      "Epoch [4/20], Loss: 0.7453\n",
      "Epoch [5/20], Loss: 0.6922\n",
      "Epoch [6/20], Loss: 0.6475\n",
      "Epoch [7/20], Loss: 0.6004\n",
      "Epoch [8/20], Loss: 0.5529\n",
      "Epoch [9/20], Loss: 0.5150\n",
      "Epoch [10/20], Loss: 0.4655\n",
      "Epoch [11/20], Loss: 0.4228\n",
      "Epoch [12/20], Loss: 0.3824\n",
      "Epoch [13/20], Loss: 0.3441\n",
      "Epoch [14/20], Loss: 0.3019\n",
      "Epoch [15/20], Loss: 0.2782\n",
      "Epoch [16/20], Loss: 0.2362\n",
      "Epoch [17/20], Loss: 0.2049\n",
      "Epoch [18/20], Loss: 0.1860\n",
      "Epoch [19/20], Loss: 0.1856\n",
      "Epoch [20/20], Loss: 0.1451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhekailow/Documents/University/FYP/submission/.venv/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/Users/zhekailow/Documents/University/FYP/submission/.venv/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 1.1010\n",
      "Epoch [2/20], Loss: 0.8852\n",
      "Epoch [3/20], Loss: 0.8067\n",
      "Epoch [4/20], Loss: 0.7442\n",
      "Epoch [5/20], Loss: 0.6889\n",
      "Epoch [6/20], Loss: 0.6428\n",
      "Epoch [7/20], Loss: 0.5954\n",
      "Epoch [8/20], Loss: 0.5482\n",
      "Epoch [9/20], Loss: 0.4986\n",
      "Epoch [10/20], Loss: 0.4628\n",
      "Epoch [11/20], Loss: 0.4092\n",
      "Epoch [12/20], Loss: 0.3716\n",
      "Epoch [13/20], Loss: 0.3287\n",
      "Epoch [14/20], Loss: 0.2862\n",
      "Epoch [15/20], Loss: 0.2590\n",
      "Epoch [16/20], Loss: 0.2257\n",
      "Epoch [17/20], Loss: 0.2039\n",
      "Epoch [18/20], Loss: 0.1734\n",
      "Epoch [19/20], Loss: 0.1578\n",
      "Epoch [20/20], Loss: 0.1301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhekailow/Documents/University/FYP/submission/.venv/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/Users/zhekailow/Documents/University/FYP/submission/.venv/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 1.1032\n",
      "Epoch [2/20], Loss: 0.8871\n",
      "Epoch [3/20], Loss: 0.8020\n",
      "Epoch [4/20], Loss: 0.7431\n",
      "Epoch [5/20], Loss: 0.6843\n",
      "Epoch [6/20], Loss: 0.6359\n",
      "Epoch [7/20], Loss: 0.5907\n",
      "Epoch [8/20], Loss: 0.5449\n",
      "Epoch [9/20], Loss: 0.4970\n",
      "Epoch [10/20], Loss: 0.4561\n",
      "Epoch [11/20], Loss: 0.4127\n",
      "Epoch [12/20], Loss: 0.3715\n",
      "Epoch [13/20], Loss: 0.3266\n",
      "Epoch [14/20], Loss: 0.2883\n",
      "Epoch [15/20], Loss: 0.2557\n",
      "Epoch [16/20], Loss: 0.2260\n",
      "Epoch [17/20], Loss: 0.1892\n",
      "Epoch [18/20], Loss: 0.1715\n",
      "Epoch [19/20], Loss: 0.1396\n",
      "Epoch [20/20], Loss: 0.1428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhekailow/Documents/University/FYP/submission/.venv/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/Users/zhekailow/Documents/University/FYP/submission/.venv/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 1.1371\n",
      "Epoch [2/20], Loss: 0.9108\n",
      "Epoch [3/20], Loss: 0.8362\n",
      "Epoch [4/20], Loss: 0.7751\n",
      "Epoch [5/20], Loss: 0.7212\n",
      "Epoch [6/20], Loss: 0.6663\n",
      "Epoch [7/20], Loss: 0.6131\n",
      "Epoch [8/20], Loss: 0.5715\n",
      "Epoch [9/20], Loss: 0.5346\n",
      "Epoch [10/20], Loss: 0.4770\n",
      "Epoch [11/20], Loss: 0.4326\n",
      "Epoch [12/20], Loss: 0.3975\n",
      "Epoch [13/20], Loss: 0.3549\n",
      "Epoch [14/20], Loss: 0.3214\n",
      "Epoch [15/20], Loss: 0.2825\n",
      "Epoch [16/20], Loss: 0.2534\n",
      "Epoch [17/20], Loss: 0.2172\n",
      "Epoch [18/20], Loss: 0.1980\n",
      "Epoch [19/20], Loss: 0.1669\n",
      "Epoch [20/20], Loss: 0.1612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhekailow/Documents/University/FYP/submission/.venv/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/Users/zhekailow/Documents/University/FYP/submission/.venv/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 1.1544\n",
      "Epoch [2/20], Loss: 0.9050\n",
      "Epoch [3/20], Loss: 0.8342\n",
      "Epoch [4/20], Loss: 0.7731\n",
      "Epoch [5/20], Loss: 0.7131\n",
      "Epoch [6/20], Loss: 0.6686\n",
      "Epoch [7/20], Loss: 0.6175\n",
      "Epoch [8/20], Loss: 0.5694\n",
      "Epoch [9/20], Loss: 0.5272\n",
      "Epoch [10/20], Loss: 0.4870\n",
      "Epoch [11/20], Loss: 0.4431\n",
      "Epoch [12/20], Loss: 0.3950\n",
      "Epoch [13/20], Loss: 0.3541\n",
      "Epoch [14/20], Loss: 0.3172\n",
      "Epoch [15/20], Loss: 0.2746\n",
      "Epoch [16/20], Loss: 0.2416\n",
      "Epoch [17/20], Loss: 0.2223\n",
      "Epoch [18/20], Loss: 0.1936\n",
      "Epoch [19/20], Loss: 0.1697\n",
      "Epoch [20/20], Loss: 0.1526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhekailow/Documents/University/FYP/submission/.venv/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/Users/zhekailow/Documents/University/FYP/submission/.venv/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 1.1427\n",
      "Epoch [2/20], Loss: 0.9112\n",
      "Epoch [3/20], Loss: 0.8342\n",
      "Epoch [4/20], Loss: 0.7745\n",
      "Epoch [5/20], Loss: 0.7169\n",
      "Epoch [6/20], Loss: 0.6638\n",
      "Epoch [7/20], Loss: 0.6153\n",
      "Epoch [8/20], Loss: 0.5747\n",
      "Epoch [9/20], Loss: 0.5327\n",
      "Epoch [10/20], Loss: 0.4903\n",
      "Epoch [11/20], Loss: 0.4440\n",
      "Epoch [12/20], Loss: 0.3997\n",
      "Epoch [13/20], Loss: 0.3585\n",
      "Epoch [14/20], Loss: 0.3368\n",
      "Epoch [15/20], Loss: 0.2978\n",
      "Epoch [16/20], Loss: 0.2594\n",
      "Epoch [17/20], Loss: 0.2227\n",
      "Epoch [18/20], Loss: 0.2094\n",
      "Epoch [19/20], Loss: 0.1797\n",
      "Epoch [20/20], Loss: 0.1640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhekailow/Documents/University/FYP/submission/.venv/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/Users/zhekailow/Documents/University/FYP/submission/.venv/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 1.2086\n",
      "Epoch [2/20], Loss: 0.9474\n",
      "Epoch [3/20], Loss: 0.8700\n",
      "Epoch [4/20], Loss: 0.8070\n",
      "Epoch [5/20], Loss: 0.7521\n",
      "Epoch [6/20], Loss: 0.7037\n",
      "Epoch [7/20], Loss: 0.6501\n",
      "Epoch [8/20], Loss: 0.6121\n",
      "Epoch [9/20], Loss: 0.5582\n",
      "Epoch [10/20], Loss: 0.5151\n",
      "Epoch [11/20], Loss: 0.4793\n",
      "Epoch [12/20], Loss: 0.4210\n",
      "Epoch [13/20], Loss: 0.3857\n",
      "Epoch [14/20], Loss: 0.3450\n",
      "Epoch [15/20], Loss: 0.3070\n",
      "Epoch [16/20], Loss: 0.2709\n",
      "Epoch [17/20], Loss: 0.2539\n",
      "Epoch [18/20], Loss: 0.2161\n",
      "Epoch [19/20], Loss: 0.1925\n",
      "Epoch [20/20], Loss: 0.1771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhekailow/Documents/University/FYP/submission/.venv/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/Users/zhekailow/Documents/University/FYP/submission/.venv/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 1.2170\n",
      "Epoch [2/20], Loss: 0.9391\n",
      "Epoch [3/20], Loss: 0.8660\n",
      "Epoch [4/20], Loss: 0.8091\n",
      "Epoch [5/20], Loss: 0.7461\n",
      "Epoch [6/20], Loss: 0.6947\n",
      "Epoch [7/20], Loss: 0.6479\n",
      "Epoch [8/20], Loss: 0.6050\n",
      "Epoch [9/20], Loss: 0.5500\n",
      "Epoch [10/20], Loss: 0.5111\n",
      "Epoch [11/20], Loss: 0.4744\n",
      "Epoch [12/20], Loss: 0.4209\n",
      "Epoch [13/20], Loss: 0.3867\n",
      "Epoch [14/20], Loss: 0.3364\n",
      "Epoch [15/20], Loss: 0.3092\n",
      "Epoch [16/20], Loss: 0.2715\n",
      "Epoch [17/20], Loss: 0.2364\n",
      "Epoch [18/20], Loss: 0.2111\n",
      "Epoch [19/20], Loss: 0.1845\n",
      "Epoch [20/20], Loss: 0.1577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhekailow/Documents/University/FYP/submission/.venv/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/Users/zhekailow/Documents/University/FYP/submission/.venv/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 1.2058\n",
      "Epoch [2/20], Loss: 0.9333\n",
      "Epoch [3/20], Loss: 0.8624\n",
      "Epoch [4/20], Loss: 0.7987\n",
      "Epoch [5/20], Loss: 0.7486\n",
      "Epoch [6/20], Loss: 0.6945\n",
      "Epoch [7/20], Loss: 0.6363\n",
      "Epoch [8/20], Loss: 0.5906\n",
      "Epoch [9/20], Loss: 0.5514\n",
      "Epoch [10/20], Loss: 0.5083\n",
      "Epoch [11/20], Loss: 0.4460\n",
      "Epoch [12/20], Loss: 0.4058\n",
      "Epoch [13/20], Loss: 0.3769\n",
      "Epoch [14/20], Loss: 0.3359\n",
      "Epoch [15/20], Loss: 0.2996\n",
      "Epoch [16/20], Loss: 0.2574\n",
      "Epoch [17/20], Loss: 0.2328\n",
      "Epoch [18/20], Loss: 0.2054\n",
      "Epoch [19/20], Loss: 0.1957\n",
      "Epoch [20/20], Loss: 0.1643\n"
     ]
    }
   ],
   "source": [
    "# Benchmarking\n",
    "# Dynamic LSTM, Average of 3, using test_size 0.2, 0.4, 0.6\n",
    "\n",
    "with open('config/lstm_dynamic.json') as f:\n",
    "    hyperparameters = json.load(f)\n",
    "    hyperparameters[\"dynamic_reset\"] = False\n",
    "    system_params_copy = system_params.copy()\n",
    "\n",
    "for test_size in [0.2, 0.4, 0.6]:\n",
    "    system_params_copy[\"test_size\"] = test_size\n",
    "    for i in range(3):\n",
    "        hyperparameters[\"hyperparameters_id\"] = f\"lstm_dynamic_test_size_{test_size}_run_{i+1}\"\n",
    "        get_results(hyperparameters, system_params_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------------+--------------------+------------------+--------------+-----------------------+------------------+------------------+--------------------------+---------------+----------------+--------------+---------------+----------------+-----------------+\n",
      "| Name          |   F1 Score (Macro) |   F1 Score (Micro) |   Final accuracy |   Final loss |   Final tensor memory |   Inference MACs |   Memory savings |   Original tensor memory |   Saved Nodes |   Saved Spikes |   Time taken |   Total Nodes |   Total Spikes |   Training MACs |\n",
      "+===============+====================+====================+==================+==============+=======================+==================+==================+==========================+===============+================+==============+===============+================+=================+\n",
      "| Test Size 0.2 |            0.74831 |           0.750223 |          75.0223 |     0.139353 |               57.8533 |       7.0384e+11 |          312.408 |                  370.261 |        422494 |          62788 |      1469.45 |        730210 |    7.63765e+07 |     1.68922e+14 |\n",
      "+---------------+--------------------+--------------------+------------------+--------------+-----------------------+------------------+------------------+--------------------------+---------------+----------------+--------------+---------------+----------------+-----------------+\n",
      "+---------------+--------------------+--------------------+------------------+--------------+-----------------------+------------------+------------------+--------------------------+---------------+----------------+--------------+---------------+----------------+-----------------+\n",
      "| Name          |   F1 Score (Macro) |   F1 Score (Micro) |   Final accuracy |   Final loss |   Final tensor memory |   Inference MACs |   Memory savings |   Original tensor memory |   Saved Nodes |   Saved Spikes |   Time taken |   Total Nodes |   Total Spikes |   Training MACs |\n",
      "+===============+====================+====================+==================+==============+=======================+==================+==================+==========================+===============+================+==============+===============+================+=================+\n",
      "| Test Size 0.4 |           0.727076 |           0.730224 |          73.0224 |     0.159279 |               57.8533 |      1.40768e+12 |          312.408 |                  370.261 |        422494 |          62788 |      1273.37 |        730210 |    7.63765e+07 |     1.26691e+14 |\n",
      "+---------------+--------------------+--------------------+------------------+--------------+-----------------------+------------------+------------------+--------------------------+---------------+----------------+--------------+---------------+----------------+-----------------+\n",
      "+---------------+--------------------+--------------------+------------------+--------------+-----------------------+------------------+------------------+--------------------------+---------------+----------------+--------------+---------------+----------------+-----------------+\n",
      "| Name          |   F1 Score (Macro) |   F1 Score (Micro) |   Final accuracy |   Final loss |   Final tensor memory |   Inference MACs |   Memory savings |   Original tensor memory |   Saved Nodes |   Saved Spikes |   Time taken |   Total Nodes |   Total Spikes |   Training MACs |\n",
      "+===============+====================+====================+==================+==============+=======================+==================+==================+==========================+===============+================+==============+===============+================+=================+\n",
      "| Test Size 0.6 |            0.70914 |           0.713172 |          71.3172 |     0.166365 |               57.8533 |      2.11152e+12 |          312.408 |                  370.261 |        422494 |          62788 |      1056.11 |        730210 |    7.63765e+07 |     8.44608e+13 |\n",
      "+---------------+--------------------+--------------------+------------------+--------------+-----------------------+------------------+------------------+--------------------------+---------------+----------------+--------------+---------------+----------------+-----------------+\n"
     ]
    }
   ],
   "source": [
    "for test_size in [0.2, 0.4, 0.6]:\n",
    "    for i in range(3):\n",
    "        results = read_test_results(f'lstm_dynamic_test_size_{test_size}_run_{i+1}')\n",
    "        if i == 0:\n",
    "            average_results = results\n",
    "        else:\n",
    "            for key in results:\n",
    "                average_results[key] += results[key]\n",
    "\n",
    "    for key in average_results:\n",
    "        average_results[key] /= 3\n",
    "\n",
    "    display_dicts_as_table([average_results], [f\"Test Size {test_size}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhekailow/Documents/University/FYP/submission/.venv/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/Users/zhekailow/Documents/University/FYP/submission/.venv/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 1.0774\n",
      "Epoch [2/20], Loss: 0.8134\n",
      "Epoch [3/20], Loss: 0.6744\n",
      "Epoch [4/20], Loss: 0.5504\n",
      "Epoch [5/20], Loss: 0.4480\n",
      "Epoch [6/20], Loss: 0.3503\n",
      "Epoch [7/20], Loss: 0.2708\n",
      "Epoch [8/20], Loss: 0.2133\n",
      "Epoch [9/20], Loss: 0.1637\n",
      "Epoch [10/20], Loss: 0.1460\n",
      "Epoch [11/20], Loss: 0.1126\n",
      "Epoch [12/20], Loss: 0.1051\n",
      "Epoch [13/20], Loss: 0.0965\n",
      "Epoch [14/20], Loss: 0.1176\n",
      "Epoch [15/20], Loss: 0.0731\n",
      "Epoch [16/20], Loss: 0.0782\n",
      "Epoch [17/20], Loss: 0.0577\n",
      "Epoch [18/20], Loss: 0.0654\n",
      "Epoch [19/20], Loss: 0.0741\n",
      "Epoch [20/20], Loss: 0.0680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhekailow/Documents/University/FYP/submission/.venv/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/Users/zhekailow/Documents/University/FYP/submission/.venv/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 1.0758\n",
      "Epoch [2/20], Loss: 0.8013\n",
      "Epoch [3/20], Loss: 0.6624\n",
      "Epoch [4/20], Loss: 0.5407\n",
      "Epoch [5/20], Loss: 0.4223\n",
      "Epoch [6/20], Loss: 0.3421\n",
      "Epoch [7/20], Loss: 0.2743\n",
      "Epoch [8/20], Loss: 0.2224\n",
      "Epoch [9/20], Loss: 0.1821\n",
      "Epoch [10/20], Loss: 0.1286\n",
      "Epoch [11/20], Loss: 0.1184\n",
      "Epoch [12/20], Loss: 0.1047\n",
      "Epoch [13/20], Loss: 0.0947\n",
      "Epoch [14/20], Loss: 0.0888\n",
      "Epoch [15/20], Loss: 0.0714\n",
      "Epoch [16/20], Loss: 0.1118\n",
      "Epoch [17/20], Loss: 0.0586\n",
      "Epoch [18/20], Loss: 0.0612\n",
      "Epoch [19/20], Loss: 0.0863\n",
      "Epoch [20/20], Loss: 0.0722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhekailow/Documents/University/FYP/submission/.venv/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/Users/zhekailow/Documents/University/FYP/submission/.venv/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 1.1159\n",
      "Epoch [2/20], Loss: 0.8094\n",
      "Epoch [3/20], Loss: 0.6778\n",
      "Epoch [4/20], Loss: 0.5474\n",
      "Epoch [5/20], Loss: 0.4576\n",
      "Epoch [6/20], Loss: 0.3488\n",
      "Epoch [7/20], Loss: 0.2666\n",
      "Epoch [8/20], Loss: 0.2081\n",
      "Epoch [9/20], Loss: 0.1844\n",
      "Epoch [10/20], Loss: 0.1554\n",
      "Epoch [11/20], Loss: 0.1166\n",
      "Epoch [12/20], Loss: 0.1162\n",
      "Epoch [13/20], Loss: 0.0944\n",
      "Epoch [14/20], Loss: 0.0891\n",
      "Epoch [15/20], Loss: 0.0783\n",
      "Epoch [16/20], Loss: 0.0799\n",
      "Epoch [17/20], Loss: 0.0977\n",
      "Epoch [18/20], Loss: 0.0733\n",
      "Epoch [19/20], Loss: 0.0437\n",
      "Epoch [20/20], Loss: 0.0516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhekailow/Documents/University/FYP/submission/.venv/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/Users/zhekailow/Documents/University/FYP/submission/.venv/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 1.1484\n",
      "Epoch [2/20], Loss: 0.8108\n",
      "Epoch [3/20], Loss: 0.6770\n",
      "Epoch [4/20], Loss: 0.5405\n",
      "Epoch [5/20], Loss: 0.4230\n",
      "Epoch [6/20], Loss: 0.3444\n",
      "Epoch [7/20], Loss: 0.2464\n",
      "Epoch [8/20], Loss: 0.1966\n",
      "Epoch [9/20], Loss: 0.1508\n",
      "Epoch [10/20], Loss: 0.1226\n",
      "Epoch [11/20], Loss: 0.0972\n",
      "Epoch [12/20], Loss: 0.0817\n",
      "Epoch [13/20], Loss: 0.0991\n",
      "Epoch [14/20], Loss: 0.0800\n",
      "Epoch [15/20], Loss: 0.0619\n",
      "Epoch [16/20], Loss: 0.0615\n",
      "Epoch [17/20], Loss: 0.0712\n",
      "Epoch [18/20], Loss: 0.0621\n",
      "Epoch [19/20], Loss: 0.0541\n",
      "Epoch [20/20], Loss: 0.0521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhekailow/Documents/University/FYP/submission/.venv/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/Users/zhekailow/Documents/University/FYP/submission/.venv/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 1.1393\n",
      "Epoch [2/20], Loss: 0.8173\n",
      "Epoch [3/20], Loss: 0.6606\n",
      "Epoch [4/20], Loss: 0.5331\n",
      "Epoch [5/20], Loss: 0.4294\n",
      "Epoch [6/20], Loss: 0.3200\n",
      "Epoch [7/20], Loss: 0.2455\n",
      "Epoch [8/20], Loss: 0.1789\n",
      "Epoch [9/20], Loss: 0.1498\n",
      "Epoch [10/20], Loss: 0.1154\n",
      "Epoch [11/20], Loss: 0.1052\n",
      "Epoch [12/20], Loss: 0.0980\n",
      "Epoch [13/20], Loss: 0.0756\n",
      "Epoch [14/20], Loss: 0.0617\n",
      "Epoch [15/20], Loss: 0.0586\n",
      "Epoch [16/20], Loss: 0.0905\n",
      "Epoch [17/20], Loss: 0.0567\n",
      "Epoch [18/20], Loss: 0.0459\n",
      "Epoch [19/20], Loss: 0.0850\n",
      "Epoch [20/20], Loss: 0.0622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhekailow/Documents/University/FYP/submission/.venv/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/Users/zhekailow/Documents/University/FYP/submission/.venv/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 1.1323\n",
      "Epoch [2/20], Loss: 0.8157\n",
      "Epoch [3/20], Loss: 0.6558\n",
      "Epoch [4/20], Loss: 0.5313\n",
      "Epoch [5/20], Loss: 0.4075\n",
      "Epoch [6/20], Loss: 0.3118\n",
      "Epoch [7/20], Loss: 0.2503\n",
      "Epoch [8/20], Loss: 0.1821\n",
      "Epoch [9/20], Loss: 0.1477\n",
      "Epoch [10/20], Loss: 0.1230\n",
      "Epoch [11/20], Loss: 0.1087\n",
      "Epoch [12/20], Loss: 0.0759\n",
      "Epoch [13/20], Loss: 0.0812\n",
      "Epoch [14/20], Loss: 0.0753\n",
      "Epoch [15/20], Loss: 0.0844\n",
      "Epoch [16/20], Loss: 0.0878\n",
      "Epoch [17/20], Loss: 0.0670\n",
      "Epoch [18/20], Loss: 0.0587\n",
      "Epoch [19/20], Loss: 0.0575\n",
      "Epoch [20/20], Loss: 0.0435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhekailow/Documents/University/FYP/submission/.venv/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/Users/zhekailow/Documents/University/FYP/submission/.venv/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 1.1771\n",
      "Epoch [2/20], Loss: 0.8133\n",
      "Epoch [3/20], Loss: 0.6349\n",
      "Epoch [4/20], Loss: 0.4695\n",
      "Epoch [5/20], Loss: 0.3501\n",
      "Epoch [6/20], Loss: 0.2787\n",
      "Epoch [7/20], Loss: 0.1916\n",
      "Epoch [8/20], Loss: 0.1483\n",
      "Epoch [9/20], Loss: 0.1140\n",
      "Epoch [10/20], Loss: 0.0935\n",
      "Epoch [11/20], Loss: 0.0886\n",
      "Epoch [12/20], Loss: 0.0679\n",
      "Epoch [13/20], Loss: 0.0834\n",
      "Epoch [14/20], Loss: 0.0646\n",
      "Epoch [15/20], Loss: 0.0520\n",
      "Epoch [16/20], Loss: 0.0491\n",
      "Epoch [17/20], Loss: 0.0632\n",
      "Epoch [18/20], Loss: 0.0588\n",
      "Epoch [19/20], Loss: 0.0707\n",
      "Epoch [20/20], Loss: 0.0400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhekailow/Documents/University/FYP/submission/.venv/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/Users/zhekailow/Documents/University/FYP/submission/.venv/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 1.2300\n",
      "Epoch [2/20], Loss: 0.8349\n",
      "Epoch [3/20], Loss: 0.6543\n",
      "Epoch [4/20], Loss: 0.5064\n",
      "Epoch [5/20], Loss: 0.3813\n",
      "Epoch [6/20], Loss: 0.2756\n",
      "Epoch [7/20], Loss: 0.2137\n",
      "Epoch [8/20], Loss: 0.1449\n",
      "Epoch [9/20], Loss: 0.1129\n",
      "Epoch [10/20], Loss: 0.0895\n",
      "Epoch [11/20], Loss: 0.0819\n",
      "Epoch [12/20], Loss: 0.0814\n",
      "Epoch [13/20], Loss: 0.0786\n",
      "Epoch [14/20], Loss: 0.0552\n",
      "Epoch [15/20], Loss: 0.0392\n",
      "Epoch [16/20], Loss: 0.0573\n",
      "Epoch [17/20], Loss: 0.0725\n",
      "Epoch [18/20], Loss: 0.0491\n",
      "Epoch [19/20], Loss: 0.0645\n",
      "Epoch [20/20], Loss: 0.0697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhekailow/Documents/University/FYP/submission/.venv/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/Users/zhekailow/Documents/University/FYP/submission/.venv/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 1.1665\n",
      "Epoch [2/20], Loss: 0.8124\n",
      "Epoch [3/20], Loss: 0.6363\n",
      "Epoch [4/20], Loss: 0.4874\n",
      "Epoch [5/20], Loss: 0.3518\n",
      "Epoch [6/20], Loss: 0.2524\n",
      "Epoch [7/20], Loss: 0.1875\n",
      "Epoch [8/20], Loss: 0.1421\n",
      "Epoch [9/20], Loss: 0.1099\n",
      "Epoch [10/20], Loss: 0.0955\n",
      "Epoch [11/20], Loss: 0.0832\n",
      "Epoch [12/20], Loss: 0.0578\n",
      "Epoch [13/20], Loss: 0.0754\n",
      "Epoch [14/20], Loss: 0.0813\n",
      "Epoch [15/20], Loss: 0.0485\n",
      "Epoch [16/20], Loss: 0.0385\n",
      "Epoch [17/20], Loss: 0.0427\n",
      "Epoch [18/20], Loss: 0.0553\n",
      "Epoch [19/20], Loss: 0.0678\n",
      "Epoch [20/20], Loss: 0.0829\n"
     ]
    }
   ],
   "source": [
    "# Benchmarking\n",
    "# Dynamic LSTM, Average of 3, using test_size 0.2, 0.4, 0.6\n",
    "\n",
    "with open('config/baseline_dynamic_noreset.json') as f:\n",
    "    hyperparameters = json.load(f)\n",
    "    system_params_copy = system_params.copy()\n",
    "\n",
    "for test_size in [0.2, 0.4, 0.6]:\n",
    "    system_params_copy[\"test_size\"] = test_size\n",
    "    for i in range(3):\n",
    "        hyperparameters[\"hyperparameters_id\"] = f\"mlp_dynamic_test_size_{test_size}_run_{i+1}\"\n",
    "        get_results(hyperparameters, system_params_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
